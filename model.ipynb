{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install Pillow matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "from torch.utils.data import random_split\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = './dataset/dataset.csv'\n",
    "image_path = './data/abo-images-small/images/small/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "def show_image(image_url):\n",
    "    # Load the image using PIL\n",
    "    img = Image.open(image_url)\n",
    "\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off') \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(f'{image_path}6a/6a8d8df6.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLabelImageDataset(Dataset):\n",
    "    def __init__(self, file_path, img_dir, transform=None):\n",
    "        # read csv file\n",
    "        self.data = pd.read_csv(file_path)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        \n",
    "        # Convert category labels to unique indices\n",
    "        self.category_labels = {}\n",
    "        for i in range(1, 7):\n",
    "            column_name = f'category_{i}'\n",
    "            self.data[column_name] = self.data[column_name].fillna('UNK')\n",
    "            self.data[f'{column_name}_idx'] = self.data[column_name].astype('category').cat.codes\n",
    "            self.category_labels[column_name] = dict(enumerate(self.data[column_name].astype('category').cat.categories))\n",
    "        \n",
    "        self.num_categories = 6\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.img_dir, self.data.iloc[idx, 2])\n",
    "        image = Image.open(img_name)\n",
    "        \n",
    "        labels = []\n",
    "        for i in range(1, 7):\n",
    "            labels.append(self.data.iloc[idx, -(self.num_categories - (i - 1))])\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, torch.tensor(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "batch_size = 32\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MultiLabelImageDataset(dataset_path, image_path, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_size = len(dataset)\n",
    "train_size = int(0.7 * dataset_size)  # 70% training\n",
    "dev_size = int(0.15 * dataset_size)   # 15% validation \n",
    "test_size = dataset_size - train_size - dev_size  # 15% test\n",
    "\n",
    "# randomly split the dataset\n",
    "train_dataset, dev_dataset, test_dataset = random_split(dataset, [train_size, dev_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoaders for each dataset\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "dev_dataloader = DataLoader(dev_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiTaskCNN(nn.Module):\n",
    "    def __init__(self, num_classes_list):\n",
    "        super(MultiTaskCNN, self).__init__()\n",
    "\n",
    "        # feature extraction block\n",
    "        self.conv_block = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "\n",
    "        # fully connected layers\n",
    "        self.fc_block = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(256 * 14 * 14, 512),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        # classifier layers for each category level\n",
    "        self.fc1 = nn.Linear(512, num_classes_list[0])\n",
    "        self.fc2 = nn.Linear(512, num_classes_list[1])\n",
    "        self.fc3 = nn.Linear(512, num_classes_list[2])\n",
    "        self.fc4 = nn.Linear(512, num_classes_list[3])\n",
    "        self.fc5 = nn.Linear(512, num_classes_list[4])\n",
    "        self.fc6 = nn.Linear(512, num_classes_list[5])\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Shared features\n",
    "        x = self.conv_block(x)\n",
    "        x = self.fc_block(x)\n",
    "\n",
    "        # separate classifier layers for \n",
    "        output1 = self.fc1(x)\n",
    "        output2 = self.fc2(x)\n",
    "        output3 = self.fc3(x)\n",
    "        output4 = self.fc4(x)\n",
    "        output5 = self.fc5(x)\n",
    "        output6 = self.fc6(x)\n",
    "\n",
    "        return output1, output2, output3, output4, output5, output6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
